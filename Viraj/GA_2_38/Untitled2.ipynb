{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woZ8oZKlyUYV"
      },
      "outputs": [],
      "source": [
        "###-----------------\n",
        "### Import Libraries\n",
        "###-----------------\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from collections.abc import Callable\n",
        "from typing import Literal\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "en6ExNAFyhEi",
        "outputId": "689d0bc1-cd8f-4924-c007-4f9152b4aad7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 Phusical GPUs 0 Logical GPUs\n"
          ]
        }
      ],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "\n",
        "try:\n",
        "    for g in gpus:\n",
        "        tf.config.experimental.set_memory_growth(g, True)\n",
        "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
        "    print (len(gpus), 'Phusical GPUs', len(logical_gpus), 'Logical GPUs')\n",
        "except:\n",
        "    print ('invalid device')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_j1jPC9yrS_"
      },
      "outputs": [],
      "source": [
        "### Some parameters\n",
        "###----------------\n",
        "\n",
        "inpDir = '/home/dai/Documents/DNN/7.DNN/input'\n",
        "outDir = '../output'\n",
        "modelDir = '../models'\n",
        "subDir = 'flower_photos'\n",
        "altName = 'cnn_base'\n",
        "\n",
        "RANDOM_STATE = 24 # REMEMBER: to remove at the time of promotion to production\n",
        "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible  results\n",
        "\n",
        "\n",
        "EPOCHS = 10 # number of epochs\n",
        "ALPHA = 0.001 # learning rate\n",
        "TEST_SIZE = 0.2\n",
        "BATCH_SIZE = 32\n",
        "LR_PATIENCE = 10\n",
        "FACTOR_LR = 0.5\n",
        "PATIENCE = 20\n",
        "IMG_HEIGHT = 190\n",
        "IMG_WIDTH = 190\n",
        "\n",
        "# parameters for Matplotlib\n",
        "params = {'legend.fontsize': 'x-large',\n",
        "          'figure.figsize': (15, 8),\n",
        "          'axes.labelsize': 'x-large',\n",
        "          'axes.titlesize':'x-large',\n",
        "          'xtick.labelsize':'x-large',\n",
        "          'ytick.labelsize':'x-large'\n",
        "         }\n",
        "\n",
        "CMAP = 'coolwarm' # plt.cm.Spectral\n",
        "\n",
        "plt.rcParams.update(params)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27pqYiZhywYM",
        "outputId": "5aca0c0a-63f0-4354-bef5-de3c35713a86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\n",
            "228813984/228813984 [==============================] - 8s 0us/step\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url,\n",
        "                                  fname='flower_photos',\n",
        "                                  untar=True)\n",
        "\n",
        "data_dir = pathlib.Path(data_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPcjMUpEy0gg",
        "outputId": "33656750-ec63-4dca-e59d-72b7835e72d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['dandelion', 'tulips', 'daisy', 'sunflowers', 'roses', 'LICENSE.txt']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtibwBATy22X",
        "outputId": "0de7aff8-739b-4cbc-9608-0a99d7e550ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ],
      "source": [
        "#create traning data\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir, #path to the data directory\n",
        "    validation_split = TEST_SIZE, #what ratio of validation data\n",
        "    subset = 'training', #purpose\n",
        "    seed = RANDOM_STATE,\n",
        "    image_size = [IMG_HEIGHT, IMG_WIDTH],\n",
        "    batch_size = BATCH_SIZE\n",
        ")\n",
        "\n",
        "#create test data\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir, #path to the data directory\n",
        "    validation_split = TEST_SIZE, #what ratio of validation data\n",
        "    subset = 'validation', #purpose\n",
        "    seed = RANDOM_STATE,\n",
        "    image_size = [IMG_HEIGHT, IMG_WIDTH],\n",
        "    batch_size = BATCH_SIZE\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMRQEfgby_jf",
        "outputId": "fca870e1-e0fd-4540-f8d6-e7a4f6b7d645"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# is it picking class names\n",
        "class_names = train_ds.class_names\n",
        "class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkkOd9aWzFeK"
      },
      "outputs": [],
      "source": [
        "train_ds = train_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "\n",
        "test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lNwuA2EzI6U"
      },
      "outputs": [],
      "source": [
        "# Build model\n",
        "dor1 = 0.01\n",
        "#knl_reg = tf.keras.regularizers.L2(l2 = 0)\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "# model.add(tf.keras.layers.RandomZoom(height_factor=(-0.2, -0.2), width_factor=(-0.2, -0.2)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Rescaling(1/255.)), # Convert between 0 and 1\n",
        "model.add(tf.keras.layers.RandomFlip(\"horizontal\"))\n",
        "model.add(tf.keras.layers.RandomRotation((-0.2, 0.3)))\n",
        "\n",
        "##-------\n",
        "### Set 1\n",
        "###-------\n",
        "# Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(8, (3,3))), # 188 x 188 x 8\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "### Pooling\n",
        "# model.add(tf.keras.layers.MaxPool2D(2, 2)), # 94 x 94 x 8\n",
        "\n",
        "###-------\n",
        "### Set 2\n",
        "###-------\n",
        "# Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(16, (3,3))), # 92 x 92 x 16\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "### Pooling\n",
        "model.add(tf.keras.layers.MaxPool2D(2, 2)), # 46 x 46 x 16\n",
        "\n",
        "###-------\n",
        "### Set 3\n",
        "###-------\n",
        "# Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(32, (3,3))), # 44 x 44 x 32\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "### Pooling\n",
        "model.add(tf.keras.layers.MaxPool2D(2, 2)), # 22 x 22 x 32\n",
        "\n",
        "###-------\n",
        "### Set 4\n",
        "###-------\n",
        "# Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(64, (3,3))), # 20 x 20 x 64\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "### Pooling\n",
        "model.add(tf.keras.layers.MaxPool2D(2, 2)), # 10 x 10 x 64\n",
        "\n",
        "###-------\n",
        "### Set 5\n",
        "###-------\n",
        "# Conv layer\n",
        "model.add(tf.keras.layers.Conv2D(128, (3,3))), # 8 x 8 x 128\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "### Pooling\n",
        "model.add(tf.keras.layers.MaxPool2D(2, 2)), # 4 x 4 x 128\n",
        "\n",
        "###-------\n",
        "### Set 6\n",
        "###-------\n",
        "\n",
        "model.add(tf.keras.layers.Conv2D(256, (3,3))), # 2 x 2 x 256\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "###------------\n",
        "### Head Start\n",
        "###------------\n",
        "model.add(tf.keras.layers.Flatten()), # Flatten\n",
        "\n",
        "model.add(tf.keras.layers.Dense(256)), # Dense 1\n",
        "\n",
        "# model.add(tf.keras.layers.BatchNormalization()),\n",
        "model.add(tf.keras.layers.Activation('relu')),\n",
        "\n",
        "# model.add(tf.keras.layers.Dropout(rate=dor1, seed=RANDOM_STATE))\n",
        "\n",
        "model.add(tf.keras.layers.Dense(5)) #Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HFV_4VBMzPhh"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=PATIENCE,\n",
        "    mode = 'auto',\n",
        "    baseline = None,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True,\n",
        "    start_from_epoch=0,\n",
        ")\n",
        "lr_decay = tf.keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=FACTOR_LR,\n",
        "    patience=LR_PATIENCE,\n",
        "    verbose=1,\n",
        "    mode='auto',\n",
        "\n",
        ")\n",
        "\n",
        "#define model file path\n",
        "modelFile = os.path.join(modelDir, subDir, altName)\n",
        "\n",
        "#define checkpoint callback\n",
        "model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    modelFile,\n",
        "    monitor = 'val_loss',\n",
        "    verbose = 1,\n",
        "    save_best_only = True,\n",
        "    save_weights_only = True,\n",
        "    mode = 'auto'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxXJu0l4zTko"
      },
      "outputs": [],
      "source": [
        "optim = tf.keras.optimizers.AdamW(learning_rate = ALPHA)\n",
        "\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy( from_logits = True)\n",
        "\n",
        "model.compile(optimizer = optim, loss = loss_fn, metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DKysaxWzWQD",
        "outputId": "ba3bf26b-d7ce-4b67-cc99-2eef94edd01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "72/92 [======================>.......] - ETA: 48s - loss: 1.4122 - accuracy: 0.3598"
          ]
        }
      ],
      "source": [
        "history = model.fit(train_ds, validation_data=test_ds,\n",
        "                    epochs=EPOCHS, verbose = 1,\n",
        "                    batch_size=BATCH_SIZE,\n",
        "                    callbacks=[early_stopping, lr_decay, model_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y72--w8_zZoA"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5I_XeUx7ze20"
      },
      "outputs": [],
      "source": [
        "###-----------------------------------\n",
        "### Function to plot Loss Curve\n",
        "###-----------------------------------\n",
        "\n",
        "def fn_plot_tf_hist(hist_df):\n",
        "    '''\n",
        "    Args:\n",
        "      hist_df : pandas Dataframe with four columns\n",
        "                For 'x' values, we will use index\n",
        "    '''\n",
        "    fig, axes = plt.subplots(1,2 , figsize = (15,6))\n",
        "\n",
        "    # properties  matplotlib.patch.Patch\n",
        "    props = dict(boxstyle='round', facecolor='aqua', alpha=0.4)\n",
        "    facecolor = 'cyan'\n",
        "    fontsize=12\n",
        "\n",
        "    # Get columns by index to eliminate any column naming error\n",
        "    y1 = hist_df.columns[0]\n",
        "    y2 = hist_df.columns[1]\n",
        "    y3 = hist_df.columns[2]\n",
        "    y4 = hist_df.columns[3]\n",
        "\n",
        "    # Where was min loss\n",
        "    best = hist_df[hist_df[y3] == hist_df[y3].min()]\n",
        "\n",
        "    ax = axes[0]\n",
        "\n",
        "    hist_df.plot(y = [y1,y3], ax = ax, colormap=CMAP)\n",
        "\n",
        "\n",
        "    # little beautification\n",
        "    txtFmt = \"{}: \\n  train: {:6.4f}\\n   test: {:6.4f}\"\n",
        "    txtstr = txtFmt.format(y1.capitalize(),\n",
        "                           hist_df.iloc[-1][y1],\n",
        "                           hist_df.iloc[-1][y3]) #text to plot\n",
        "\n",
        "    # place a text box in upper middle in axes coords\n",
        "    ax.text(0.3, 0.95, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
        "            verticalalignment='top', bbox=props)\n",
        "\n",
        "    # Mark arrow at lowest\n",
        "    ax.annotate(f'Min: {best[y3].to_numpy()[0]:6.4f}', # text to print\n",
        "                xy=(best.index.to_numpy(), best[y3].to_numpy()[0]), # Arrow start\n",
        "                xytext=(best.index.to_numpy()-1, best[y3].to_numpy()[0]), # location of text\n",
        "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
        "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
        "\n",
        "    # Draw vertical line at best value\n",
        "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
        "\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(y1.capitalize())\n",
        "    ax.set_title('Errors')\n",
        "    ax.grid();\n",
        "    ax.legend(loc = 'upper left') # model legend to upper left\n",
        "\n",
        "    ax = axes[1]\n",
        "\n",
        "    hist_df.plot( y = [y2, y4], ax = ax, colormap=CMAP)\n",
        "\n",
        "    # little beautification\n",
        "    txtFmt = \"{}: \\n  train: {:6.4f}\\n  test:  {:6.4f}\"\n",
        "    txtstr = txtFmt.format(y2.capitalize(),\n",
        "                           hist_df.iloc[-1][y2],\n",
        "                           hist_df.iloc[-1][y4]) #text to plot\n",
        "\n",
        "    # place a text box in upper middle in axes coords\n",
        "    ax.text(0.3, 0.2, txtstr, transform=ax.transAxes, fontsize=fontsize,\n",
        "            verticalalignment='top', bbox=props)\n",
        "\n",
        "    # Mark arrow at lowest\n",
        "    ax.annotate(f'Best: {best[y4].to_numpy()[0]:6.4f}', # text to print\n",
        "                xy=(best.index.to_numpy(), best[y4].to_numpy()[0]), # Arrow start\n",
        "                xytext=(best.index.to_numpy()-1, best[y4].to_numpy()[0]), # location of text\n",
        "                fontsize=fontsize, va='bottom', ha='right',bbox=props, # beautification of text\n",
        "                arrowprops=dict(facecolor=facecolor, shrink=0.05)) # arrow\n",
        "\n",
        "\n",
        "    # Draw vertical line at best value\n",
        "    ax.axvline(x = best.index.to_numpy(), color = 'green', linestyle='-.', lw = 3);\n",
        "\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(y2.capitalize())\n",
        "    ax.grid()\n",
        "    ax.legend(loc = 'lower left')\n",
        "\n",
        "    plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybhdOVhhzh1R"
      },
      "outputs": [],
      "source": [
        "loss_df = pd.DataFrame(history.history)\n",
        "fn_plot_tf_hist(loss_df)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}