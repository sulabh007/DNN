{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "kFZRpLpK02pB"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "deSnZmVy02pF"
   },
   "source": [
    "# Deep Neural Networks\n",
    "\n",
    "## Text Generation with RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "rt0pfyeA02pK"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:28:59.591539: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "###-----------------\n",
    "### Import Libraries\n",
    "###-----------------\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from collections.abc import Callable\n",
    "from typing import Literal\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "# try:\n",
    "#     for g in gpus:\n",
    "#         tf.config.experimental.set_memory_growth(g, True)\n",
    "#     logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#     print (len(gpus), 'Phusical GPUs', len(logical_gpus), 'Logical GPUs')\n",
    "# except:\n",
    "#     print ('invalid device')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "__T9cczP02pL"
   },
   "outputs": [],
   "source": [
    "###----------------\n",
    "### Some parameters\n",
    "###----------------\n",
    "\n",
    "inpDir = '../../input'\n",
    "outDir = '../output'\n",
    "subDir = 'Shakespeare'\n",
    "modelDir = '.../models'\n",
    "\n",
    "RANDOM_STATE = 24 # REMEMBER: to remove at the time of promotion to production\n",
    "np.random.seed(RANDOM_STATE) # Set Random Seed for reproducible  results\n",
    "\n",
    "EPOCHS = 10 # number of epochs\n",
    "ALPHA = 0.01 # learning rate\n",
    "TEST_SIZE = 0.2\n",
    "BATCH_SIZE = 32\n",
    "TRAIN_SIZE = 256 # fix size of train set sot that we have batches of same size\n",
    "PATIENCE = 10\n",
    "\n",
    "# parameters for Matplotlib\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 8),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'\n",
    "         }\n",
    "\n",
    "CMAP = 'coolwarm' # plt.cm.Spectral\n",
    "\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bhVN20X02pN"
   },
   "source": [
    "## Generate Data Set\n",
    "Shakespeare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LXZ37P4G02pP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1115395"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = open('shakespeare.txt', 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate (vocab)}\n",
    "\n",
    "#char2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['\\n', ' ', '!', '$', '&', \"'\", ',', '-', '.', '3', ':', ';', '?',\n",
       "       'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
       "       'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm',\n",
       "       'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'],\n",
       "      dtype='<U1')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char = np.array(vocab)\n",
    "\n",
    "idx2char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115395,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int = np.array([char2idx[c] for c in text])\n",
    "\n",
    "text_as_int.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 47, 56, ...,  8,  0,  0])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_as_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'First Citizen:'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'F'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2char[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:03.493191: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "# print(list(dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11043"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = 100\n",
    "\n",
    "example_per_epoch = len(text) // (seq_length+1)\n",
    "\n",
    "example_per_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 | F\n",
      "47 | i\n",
      "56 | r\n",
      "57 | s\n",
      "58 | t\n",
      "1 |  \n",
      "15 | C\n",
      "47 | i\n",
      "58 | t\n",
      "47 | i\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:03.968221: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(10):\n",
    "    print(i.numpy(), '|', idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:04.165783: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 14 43 44 53 56 43  1 61 43\n",
      "  1 54 56 53 41 43 43 42  1 39 52 63  1 44 59 56 58 46 43 56  6  1 46 43\n",
      " 39 56  1 51 43  1 57 54 43 39 49  8  0  0 13 50 50 10  0 31 54 43 39 49\n",
      "  6  1 57 54 43 39 49  8  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10\n",
      "  0 37 53 59  1], shape=(101,), dtype=int64)\n",
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "\n",
      "\n",
      "tf.Tensor(\n",
      "[39 56 43  1 39 50 50  1 56 43 57 53 50 60 43 42  1 56 39 58 46 43 56  1\n",
      " 58 53  1 42 47 43  1 58 46 39 52  1 58 53  1 44 39 51 47 57 46 12  0  0\n",
      " 13 50 50 10  0 30 43 57 53 50 60 43 42  8  1 56 43 57 53 50 60 43 42  8\n",
      "  0  0 18 47 56 57 58  1 15 47 58 47 64 43 52 10  0 18 47 56 57 58  6  1\n",
      " 63 53 59  1 49], shape=(101,), dtype=int64)\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sequence = dataset.batch(seq_length + 1 , \n",
    "                         drop_remainder=True) # convert to batch\n",
    "\n",
    "for item in sequence.take(2):\n",
    "    \n",
    "    print(item)\n",
    "    \n",
    "    print(repr(''.join(idx2char[item.numpy()] ) ) ) #take index values and convert to char\n",
    "    \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fn_split_X_y (seq): # bring in sequence of length 101\n",
    "    \n",
    "    input_text = seq[:-1] # input is first 100 chars\n",
    "    \n",
    "    output_text = seq[1:] # output is first 100 chars\n",
    "    \n",
    "    return input_text, output_text\n",
    "\n",
    "dataset = sequence.map(fn_split_X_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "--------------------------------------------------\n",
      "'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you '\n",
      "'re all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:04.621210: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataset.take (2):\n",
    "    print (repr(''.join(idx2char[X.numpy()] ) ) ) # X data\n",
    "    print (repr(''.join(idx2char[y.numpy()] ) ) ) # y data\n",
    "    print ('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:05.574376: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-02 13:29:05.576798: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-02 13:29:05.578498: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "\n",
    "embedding_dim = 256\n",
    "\n",
    "rnn_units = 1024\n",
    "\n",
    "def build_model(vocab_size, \n",
    "                embedding_dim, \n",
    "                rnn_units, \n",
    "                batch_size = BATCH_SIZE):\n",
    "    \n",
    "    model = tf.keras.Sequential([\n",
    "        \n",
    "        tf.keras.layers.Embedding(vocab_size,\n",
    "                                  embedding_dim,\n",
    "                                  batch_input_shape = [batch_size, None]),\n",
    "        \n",
    "        tf.keras.layers.GRU(rnn_units,\n",
    "                            return_sequences = True,\n",
    "                            stateful = True,\n",
    "                            recurrent_initializer = 'glorot_uniform'),\n",
    "        \n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(vocab_size, \n",
    "                    embedding_dim, \n",
    "                    rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (32, None, 256)           16640     \n",
      "                                                                 \n",
      " gru (GRU)                   (32, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense (Dense)               (32, None, 65)            66625     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021,569\n",
      "Trainable params: 4,021,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:05.780195: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-02 13:29:05.781139: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "for X, y in dataset.take(2):\n",
    "    \n",
    "    y_pred = model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 100, 65])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.losses.SparseCategoricalCrossentropy(from_logits= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "oa8WtTI202pn",
    "outputId": "3f0ca548-7715-47c7-b4fd-fac7924bc060"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss=loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "chkPtPath = os.path.join(modelDir, subDir)\n",
    "\n",
    "chkPtPrefix = os.path.join(chkPtPath, 'chkpt_{epoch}')\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=chkPtPrefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 13:29:08.445742: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-02 13:29:08.446394: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int64 and shape [1115395]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-12-02 13:29:08.808395: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-02 13:29:08.811306: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-02 13:29:08.813420: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-12-02 13:29:09.646968: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-02 13:29:09.649172: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-02 13:29:09.650814: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345/345 [==============================] - 1123s 3s/step - loss: 2.3198\n",
      "Epoch 2/10\n",
      "345/345 [==============================] - 1107s 3s/step - loss: 1.6916\n",
      "Epoch 3/10\n",
      "345/345 [==============================] - 1125s 3s/step - loss: 1.4993\n",
      "Epoch 4/10\n",
      "345/345 [==============================] - 1127s 3s/step - loss: 1.4050\n",
      "Epoch 5/10\n",
      "345/345 [==============================] - 1121s 3s/step - loss: 1.3450\n",
      "Epoch 6/10\n",
      "345/345 [==============================] - 1121s 3s/step - loss: 1.2980\n",
      "Epoch 7/10\n",
      "345/345 [==============================] - 1116s 3s/step - loss: 1.2560\n",
      "Epoch 8/10\n",
      "345/345 [==============================] - 1118s 3s/step - loss: 1.2151\n",
      "Epoch 9/10\n",
      "345/345 [==============================] - 1088s 3s/step - loss: 1.1778\n",
      "Epoch 10/10\n",
      "273/345 [======================>.......] - ETA: 3:48 - loss: 1.1394"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.latest_checkpoint(chkPtPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-02 12:22:26.335077: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-12-02 12:22:26.337630: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-12-02 12:22:26.339380: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'endswith'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text createaon using RNN.ipynb Cell 33\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m build_model(vocab_size, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m                     embedding_dim, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     rnn_units,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m model\u001b[39m.\u001b[39;49mload_weights(tf\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mlatest_checkpoint(chkPtPath))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y610sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/Documents/Machine Learning/.conda/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Machine Learning/.conda/lib/python3.11/site-packages/keras/saving/legacy/saving_utils.py:368\u001b[0m, in \u001b[0;36mis_hdf5_filepath\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mis_hdf5_filepath\u001b[39m(filepath):\n\u001b[1;32m    367\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m--> 368\u001b[0m         filepath\u001b[39m.\u001b[39;49mendswith(\u001b[39m\"\u001b[39m\u001b[39m.h5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    369\u001b[0m         \u001b[39mor\u001b[39;00m filepath\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.keras\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    370\u001b[0m         \u001b[39mor\u001b[39;00m filepath\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39m.hdf5\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    371\u001b[0m     )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'endswith'"
     ]
    }
   ],
   "source": [
    "model = build_model(vocab_size, \n",
    "                    embedding_dim, \n",
    "                    rnn_units,\n",
    "                    batch_size = 1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(chkPtPath))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build(tf.TensorShape([1, None] ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text(model, start_string):\n",
    "    num_generate = 1000\n",
    "    \n",
    "    input_eval = [char2idx[c] for c in start_string] # [37, 48, 56]\n",
    "    \n",
    "    print(f'Input: {start_string} | {input_eval}')\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    model.reset_states()\n",
    "    for i in range (num_generate):\n",
    "        \n",
    "        prediction = model(input_eval)\n",
    "        \n",
    "        prediction = tf.squeeze(prediction, 0)\n",
    "        \n",
    "        predict_td = tf.random.categorical(prediction, num_samples=1)[-1,0].numpy()\n",
    "        input_eval = tf.expand_dims([predict_td], 0)\n",
    "        text_generated.append(idx2char[predict_td])\n",
    "        \n",
    "    return start_string + ''.join(text_generated)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chart2idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text createaon using RNN.ipynb Cell 36\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m gen_text(model, \u001b[39m'\u001b[39;49m\u001b[39mROMEO:\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text createaon using RNN.ipynb Cell 36\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_text\u001b[39m(model, start_string):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     num_generate \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     input_eval \u001b[39m=\u001b[39m [chart2idx[c] \u001b[39mfor\u001b[39;49;00m c \u001b[39min\u001b[39;49;00m start_string]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     input_eval \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(input_eval, \u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     text_generated \u001b[39m=\u001b[39m []\n",
      "\u001b[1;32m/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text createaon using RNN.ipynb Cell 36\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_text\u001b[39m(model, start_string):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     num_generate \u001b[39m=\u001b[39m \u001b[39m10000\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     input_eval \u001b[39m=\u001b[39m [chart2idx[c] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m start_string]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     input_eval \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mexpand_dims(input_eval, \u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/dai/Documents/DNN/Dec2_DNN/S20_tf_Text%20createaon%20using%20RNN.ipynb#Y614sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     text_generated \u001b[39m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chart2idx' is not defined"
     ]
    }
   ],
   "source": [
    "gen_text(model, 'ROMEO:')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "S05a_one_hidden_layer_with_tanh_wip.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
